# Support Vector Machines with Scikit-learn in Python

**We use the <a href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data">Breast Cancer Wisconsin (Diagnostic) Data Set</a> Dataset originally contributed by <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning</a>**

## A brief introduction to Support Verctor Machines(SVM):

- SVM is considered to be a classification approach, it but can be employed in both types of classification and regression problems. It can easily handle multiple continuous and categorical variables.

- SVM offers very high accuracy compared to other classifiers such as logistic regression, and decision trees. It separates data points using a hyperplane with the large amount of margin. So, it's also known as **Discriminative classifier**.

![Support Vector Machine](Machine Learning/sklearn examples/Support Vector Machines(SVM)/svm_separation.png)

## SVM Kernals

- SVM algorithms are known for its **Kernel**. Kernel takes a low-dimensional input space and transforms it into a higher dimensional space. In other words, you can say that it converts nonseparable problem to separable problems by adding more dimension to it.

**Linear Kernel**:
Linear kernel can be used as normal dot product any two given observations.

**Polynomial Kernel**:
Polynomial kernel is a more generalized form of the linear kernel. The polynomial kernel can distinguish curved or nonlinear input space.

**Radial Basis Function Kernel**:
Radial basis function kernel is a popular kernel function commonly used in support vector machine classification. RBF can map an input space in infinite dimensional space.

## Some Use Cases:
- Face Detection
- Bioinformation
- Handwriting Detection
- Classification of Images
